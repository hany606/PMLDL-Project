diff --git a/train.py b/train.py
index e4f2a30..d23412d 100644
--- a/train.py
+++ b/train.py
@@ -8,9 +8,9 @@ import wandb
 
 
 wandb_experiment_config = {"algorithm": 
-                                        "PPO"#"DQN"
+                                "DQN"
                           }
-env_name = "MountainCar-v0"
+env_name = "CartPole-v1"
 notes = f"Running RL algorithm ({wandb_experiment_config['algorithm']}) for env: {env_name}"
 
 wandb.init(
@@ -26,8 +26,8 @@ wandb.init(
 
 # https://github.com/openai/gym/wiki/MountainCar-v0
 env = gym.make(env_name)
-# dqn_agent = VanillaDQN(env, hidden_dim=64)
-ppo_agent = PPO(env)
+dqn_agent = VanillaDQN(env, hidden_dim=64)
+#ppo_agent = PPO(env)
 
 # After testing with the original reward of the environment, nothing was improved in training
 # So, I have changed the reward function, to test different behavior and found some improvements
@@ -47,36 +47,36 @@ eps_prob = 0.1000
 learning_rate = 0.003
 num_steps = 200
 # With num_steps=200 it improved the training and increased the reward
-# rewards = dqn_agent.train(  return_rewards=True, 
-#                             save_flag=True, 
-#                             render=False, 
-#                             save_file_path="./zoo/dqn/", 
-#                             save_file_name="best_model_dqn",
-#                             num_epochs=num_epochs, 
-#                             batch_size=batch_size, 
-#                             target_update_freq=target_update_freq,  
-#                             eps_prob=eps_prob, 
-#                             learning_rate=learning_rate, 
-#                             num_steps=num_steps,
-#                             reward_shaping_func=reward_shaping_func,
-#                             special_termination_condition=special_termination_condition,
-#                             wandb_flag=True,
-#                           )
-rewards = ppo_agent.train(  return_rewards=True, 
+rewards = dqn_agent.train(  return_rewards=True, 
                             save_flag=True, 
                             render=False, 
-                            save_file_path="./zoo/ppo/", 
-                            save_file_name="best_model_ppo",
+                            save_file_path="./zoo/dqn/", 
+                            save_file_name="best_model_dqn",
+                            num_epochs=num_epochs, 
+                            batch_size=batch_size, 
+                            target_update_freq=target_update_freq,  
+                            eps_prob=eps_prob, 
+                            learning_rate=learning_rate, 
+                            num_steps=num_steps,
                             reward_shaping_func=reward_shaping_func,
                             special_termination_condition=special_termination_condition,
                             wandb_flag=True,
-                            num_steps = num_steps,
                           )
+# rewards = ppo_agent.train(  return_rewards=True, 
+#                             save_flag=True, 
+#                             render=False, 
+#                             save_file_path="./zoo/ppo/", 
+#                             save_file_name="best_model_ppo",
+#                             reward_shaping_func=reward_shaping_func,
+#                             special_termination_condition=special_termination_condition,
+#                             wandb_flag=True,
+#                             num_steps = num_steps,
+#                           )
 
-# dqn_agent.train(num_epochs=500, batch_size=128, target_update_freq=5000, render=True, eps_prob=0.1, learning_rate=0.003, num_steps=1000)
+dqn_agent.train(num_epochs=500, batch_size=128, target_update_freq=5000, render=True, eps_prob=0.1, learning_rate=0.003, num_steps=1000)
 
-# plt.plot([i+1 for i in range(num_epochs)], rewards)
-# plt.xlabel("Epochs")
-# plt.ylabel("Reward")
-# plt.savefig("./zoo/dqn/best_model_dqn.png")
-# plt.show()
+plt.plot([i+1 for i in range(num_epochs)], rewards)
+plt.xlabel("Epochs")
+plt.ylabel("Reward")
+plt.savefig("./zoo/dqn/best_model_dqn0.png")
+plt.show()
